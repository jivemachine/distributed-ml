{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import col, expr, concat, lit, ceil, round, avg, max, mean, sum, when"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>julia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language\n",
       "0      python\n",
       "1  javascript\n",
       "2          c#\n",
       "3       julia"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"language\": ['python', 'javascript', 'c#', 'julia']}\n",
    "language = pd.DataFrame(data)\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(language)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_shape(self):\n",
    "    return (self.count(), len(self.columns))\n",
    "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|    python|\n",
      "|javascript|\n",
      "|        c#|\n",
      "|     julia|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the mpg dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data('mpg'))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "\n",
    "> The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "For each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|vehicle_cylinder_description                                  |\n",
      "+--------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 8 cylinder engine.             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(concat(\n",
    "    lit(\"The \"),\n",
    "    col(\"year\"),\n",
    "    lit(\" \"),\n",
    "    col(\"manufacturer\"),\n",
    "    lit(\" \"),\n",
    "    col(\"model\"),\n",
    "    lit(\" has a \"),\n",
    "    col(\"cyl\"),\n",
    "    lit(\" cylinder engine.\")\n",
    ").alias(\"vehicle_cylinder_description\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|transmission|\n",
      "+------------+\n",
      "|auto        |\n",
      "|manual      |\n",
      "|manual      |\n",
      "|auto        |\n",
      "|auto        |\n",
      "|manual      |\n",
      "|auto        |\n",
      "|manual      |\n",
      "|auto        |\n",
      "|manual      |\n",
      "|auto        |\n",
      "|auto        |\n",
      "|manual      |\n",
      "|auto        |\n",
      "|manual      |\n",
      "|auto        |\n",
      "|auto        |\n",
      "|auto        |\n",
      "|auto        |\n",
      "|auto        |\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "mpg.select(\n",
    "    regexp_extract(\"trans\", r\"^(\\w+)\", 1).alias(\"transmission\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "    a. What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = spark.createDataFrame(data('tips'))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|     tip_percentage|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "|0.18623962040332148|\n",
      "|0.22805017103762829|\n",
      "|0.11607142857142858|\n",
      "|0.13031914893617022|\n",
      "| 0.2185385656292287|\n",
      "| 0.1665043816942551|\n",
      "|0.14180374361883155|\n",
      "|0.10181582360570687|\n",
      "|0.16277807921866522|\n",
      "|0.20364126770060686|\n",
      "|0.18164967562557924|\n",
      "| 0.1616650532429816|\n",
      "|0.22774708410067526|\n",
      "|0.20624631703005306|\n",
      "|0.16222760290556903|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col1 = (tips.tip / tips.total_bill).alias(\"tip_percentage\") \n",
    "\n",
    "tips.select(col1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+--------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_percentage|\n",
      "+----------+----+------+------+---+------+----+--------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|            6%|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|           16%|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|           17%|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|           14%|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|           15%|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|           19%|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|           23%|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|           12%|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|           13%|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|           22%|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|           17%|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|           14%|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|           10%|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|           16%|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|           20%|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|           18%|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|           16%|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|           23%|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|           21%|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|           16%|\n",
      "+----------+----+------+------+---+------+----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.withColumn(\"tip_percentage\", concat(round((col(\"tip\")/col(\"total_bill\") * 100), 0).cast(\"int\"), lit(\"%\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.createOrReplaceTempView(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|non_smoker_female_tip_percentage|\n",
      "+--------------------------------+\n",
      "|              0.1569209707691836|\n",
      "+--------------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|smoker_female_tip_percentage|\n",
      "+----------------------------+\n",
      "|         0.18215035269941035|\n",
      "+----------------------------+\n",
      "\n",
      "+------------------------------+\n",
      "|non_smoker_male_tip_percentage|\n",
      "+------------------------------+\n",
      "|            0.1606687151291298|\n",
      "+------------------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|smoker_male_tip_percentage|\n",
      "+--------------------------+\n",
      "|        0.1527711752024851|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col1 = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT AVG((tip / total_bill)) AS non_smoker_female_tip_percentage\n",
    "    FROM tips\n",
    "    WHERE sex like 'Female' \n",
    "    AND smoker like 'No'\n",
    "    \"\"\"\n",
    ").show()\n",
    "\n",
    "col2 = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT AVG((tip / total_bill)) AS smoker_female_tip_percentage\n",
    "    FROM tips\n",
    "    WHERE sex like 'Female' \n",
    "    AND smoker like 'Yes'\n",
    "    \"\"\"\n",
    ").show()\n",
    "\n",
    "col3 = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT AVG((tip / total_bill)) AS non_smoker_male_tip_percentage\n",
    "    FROM tips\n",
    "    WHERE sex like 'Male' \n",
    "    AND smoker like 'No'\n",
    "    \"\"\"\n",
    ").show()\n",
    "\n",
    "col4 = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT AVG((tip / total_bill)) AS smoker_male_tip_percentage\n",
    "    FROM tips\n",
    "    WHERE sex like 'Male' \n",
    "    AND smoker like 'Yes'\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = tips.groupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the seattle weather dataset referenced in the lesson to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "|2012-01-07|          0.0|     7.2|     2.8| 2.3|   rain|\n",
      "|2012-01-08|          0.0|    10.0|     2.8| 2.0|    sun|\n",
      "|2012-01-09|          4.3|     9.4|     5.0| 3.4|   rain|\n",
      "|2012-01-10|          1.0|     6.1|     0.6| 3.4|   rain|\n",
      "|2012-01-11|          0.0|     6.1|    -1.1| 5.1|    sun|\n",
      "|2012-01-12|          0.0|     6.1|    -1.7| 1.9|    sun|\n",
      "|2012-01-13|          0.0|     5.0|    -2.8| 1.3|    sun|\n",
      "|2012-01-14|          4.1|     4.4|     0.6| 5.3|   snow|\n",
      "|2012-01-15|          5.3|     1.1|    -3.3| 3.2|   snow|\n",
      "|2012-01-16|          2.5|     1.7|    -2.8| 5.0|   snow|\n",
      "|2012-01-17|          8.1|     3.3|     0.0| 5.6|   snow|\n",
      "|2012-01-18|         19.8|     0.0|    -2.8| 5.0|   snow|\n",
      "|2012-01-19|         15.2|    -1.1|    -2.8| 1.6|   snow|\n",
      "|2012-01-20|         13.5|     7.2|    -1.1| 2.3|   snow|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the temperatures to farenheight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+-------------+----+-------+\n",
      "|      date|precipitation|max_fahr_temp|low_fahr_temp|wind|weather|\n",
      "+----------+-------------+-------------+-------------+----+-------+\n",
      "|2012-01-01|          0.0|         55.0|         41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|         51.0|         37.0| 4.5|   rain|\n",
      "|2012-01-03|          0.8|         53.0|         45.0| 2.3|   rain|\n",
      "|2012-01-04|         20.3|         54.0|         42.0| 4.7|   rain|\n",
      "|2012-01-05|          1.3|         48.0|         37.0| 6.1|   rain|\n",
      "|2012-01-06|          2.5|         40.0|         36.0| 2.2|   rain|\n",
      "|2012-01-07|          0.0|         45.0|         37.0| 2.3|   rain|\n",
      "|2012-01-08|          0.0|         50.0|         37.0| 2.0|    sun|\n",
      "|2012-01-09|          4.3|         49.0|         41.0| 3.4|   rain|\n",
      "|2012-01-10|          1.0|         43.0|         33.0| 3.4|   rain|\n",
      "|2012-01-11|          0.0|         43.0|         30.0| 5.1|    sun|\n",
      "|2012-01-12|          0.0|         43.0|         29.0| 1.9|    sun|\n",
      "|2012-01-13|          0.0|         41.0|         27.0| 1.3|    sun|\n",
      "|2012-01-14|          4.1|         40.0|         33.0| 5.3|   snow|\n",
      "|2012-01-15|          5.3|         34.0|         26.0| 3.2|   snow|\n",
      "|2012-01-16|          2.5|         35.0|         27.0| 5.0|   snow|\n",
      "|2012-01-17|          8.1|         38.0|         32.0| 5.6|   snow|\n",
      "|2012-01-18|         19.8|         32.0|         27.0| 5.0|   snow|\n",
      "|2012-01-19|         15.2|         30.0|         27.0| 1.6|   snow|\n",
      "|2012-01-20|         13.5|         45.0|         30.0| 2.3|   snow|\n",
      "+----------+-------------+-------------+-------------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fahrenheit = weather.select(\n",
    "    weather.date,\n",
    "    weather.precipitation,\n",
    "    round(weather.temp_max * (9/5) + 32).alias(\"max_fahr_temp\"),\n",
    "    round(weather.temp_min * (9/5) + 32).alias(\"low_fahr_temp\"),\n",
    "    weather.wind,\n",
    "    weather.weather,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_rain = weather.select(\n",
    "    regexp_extract(\"date\", r\"\\d+-(\\d{2})\", 1).alias(\"month\"),\n",
    "    weather.precipitation,\n",
    "    weather.weather,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+\n",
      "|month|precipitation|weather|\n",
      "+-----+-------------+-------+\n",
      "|   01|          0.0|drizzle|\n",
      "|   01|         10.9|   rain|\n",
      "|   01|          0.8|   rain|\n",
      "|   01|         20.3|   rain|\n",
      "|   01|          1.3|   rain|\n",
      "|   01|          2.5|   rain|\n",
      "|   01|          0.0|   rain|\n",
      "|   01|          0.0|    sun|\n",
      "|   01|          4.3|   rain|\n",
      "|   01|          1.0|   rain|\n",
      "|   01|          0.0|    sun|\n",
      "|   01|          0.0|    sun|\n",
      "|   01|          0.0|    sun|\n",
      "|   01|          4.1|   snow|\n",
      "|   01|          5.3|   snow|\n",
      "|   01|          2.5|   snow|\n",
      "|   01|          8.1|   snow|\n",
      "|   01|         19.8|   snow|\n",
      "|   01|         15.2|   snow|\n",
      "|   01|         13.5|   snow|\n",
      "+-----+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_rain.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|month|       avg_rainfall|\n",
      "+-----+-------------------+\n",
      "|   01| 3.7580645161290316|\n",
      "|   02|  3.734513274336283|\n",
      "|   03|  4.888709677419355|\n",
      "|   04| 3.1283333333333325|\n",
      "|   05| 1.6733870967741935|\n",
      "|   06| 1.1075000000000002|\n",
      "|   07|0.38870967741935486|\n",
      "|   08| 1.3201612903225806|\n",
      "|   09| 1.9624999999999997|\n",
      "|   10|  4.059677419354839|\n",
      "|   11|  5.354166666666667|\n",
      "|   12|  5.021774193548388|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_rain.groupBy(\"month\").agg(avg(\"precipitation\").alias(\"avg_rainfall\")).sort(\"month\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month, year, quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|      wind_by_year|\n",
      "+----+------------------+\n",
      "|2015|            1153.3|\n",
      "|2013|1100.7999999999997|\n",
      "|2014|            1236.5|\n",
      "|2012|1244.7000000000003|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.withColumn(\"year\", year(\"date\"))\n",
    ".groupBy(\"year\")\n",
    ".agg(sum(\"wind\")\n",
    ".alias(\"wind_by_year\"))\n",
    ".show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|drizzle|   10|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(month(\"date\") == 1)\n",
    "    .withColumn(\"month\", month(\"date\"))\n",
    "    .groupBy(\"weather\")\n",
    "    .count()\n",
    "    .show()\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the average high and low tempurature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|     avg_high_temp|     avg_temp_low|\n",
      "+------------------+-----------------+\n",
      "|26.828846153846158|14.18269230769231|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(col(\"weather\") == lit(\"sun\"))\n",
    "    .agg(avg(\"temp_max\").alias(\"avg_high_temp\"), avg(\"temp_min\").alias(\"avg_temp_low\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           avg(rain)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(weather\n",
    " .filter(year('date') == 2015)\n",
    " .filter(quarter(\"date\") == 3)\n",
    " .select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\n",
    " .agg(mean(\"rain\"))\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year| pct_days_with_rain|\n",
      "+----+-------------------+\n",
      "|2015|0.39452054794520547|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2012|0.48360655737704916|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather\n",
    "    .withColumn(\"rain\", when(col(\"precipitation\") > 0,1).otherwise(0))\n",
    "    .groupBy(year(\"date\").alias(\"year\"))\n",
    "    .agg(mean(col(\"rain\")).alias(\"pct_days_with_rain\"))\n",
    "    .show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
